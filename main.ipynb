{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willburr/humorous-headlines/blob/test-eval/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEewKMPzm6ys"
      },
      "source": [
        "### Coursework coding instructions (please also see full coursework spec)\n",
        "\n",
        "Please choose if you want to do either Task 1 or Task 2. You should write your report about one task only.\n",
        "\n",
        "For the task you choose you will need to do two approaches:\n",
        "  - Approach 1, which can use use pre-trained embeddings / models\n",
        "  - Approach 2, which should not use any pre-trained embeddings or models\n",
        "We should be able to run both approaches from the same colab file\n",
        "\n",
        "#### Running your code:\n",
        "  - Your models should run automatically when running your colab file without further intervention\n",
        "  - For each task you should automatically output the performance of both models\n",
        "  - Your code should automatically download any libraries required\n",
        "\n",
        "#### Structure of your code:\n",
        "  - You are expected to use the 'train', 'eval' and 'model_performance' functions, although you may edit these as required\n",
        "  - Otherwise there are no restrictions on what you can do in your code\n",
        "\n",
        "#### Documentation:\n",
        "  - You are expected to produce a .README file summarising how you have approached both tasks\n",
        "\n",
        "#### Reproducibility:\n",
        "  - Your .README file should explain how to replicate the different experiments mentioned in your report\n",
        "\n",
        "Good luck! We are really looking forward to seeing your reports and your model code!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSraR3PdJ2i9"
      },
      "source": [
        "# Project  Set-up\r\n",
        "\r\n",
        "The code blocks below provide the imports and necessaryset-up steps to run later sections. We import necessary libraries, set pytorch to use the GPU and load and unzip the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFcxAGnSm6y2"
      },
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import torch.optim as optim\n",
        "import codecs\n",
        "import tqdm"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM2SBsBzm6y3"
      },
      "source": [
        "# Setting random seed and device\n",
        "SEED = 1\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVWAKu6ALaCL"
      },
      "source": [
        "## Downloading and unzipping the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AEMK9jQjem-",
        "outputId": "02c0cdd8-c2ca-48a2-9e65-3ba6402ec937",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget -O train.csv https://drive.google.com/u/0/uc?id=1KS6Cxl4CJnSLkMcdgbnmEdsStlVzacWX&export=download\n",
        "!wget -O dev.csv https://drive.google.com/u/0/uc?id=19WKir5IRn83NMcVgvNDrmgcDj1UIv7kt&export=download\n",
        "!wget -O test.csv https://drive.google.com/u/0/uc?id=11pyqg27tGRC1iDo26C2b01bMETqdUwuf&export=download"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-18 16:56:57--  https://drive.google.com/u/0/uc?id=1KS6Cxl4CJnSLkMcdgbnmEdsStlVzacWX\n",
            "Resolving drive.google.com (drive.google.com)... 108.177.127.100, 108.177.127.113, 108.177.127.102, ...\n",
            "Connecting to drive.google.com (drive.google.com)|108.177.127.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-08-cc-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/eob5hsg3v7suni03f0jb173anaqnksc8/1613667375000/13802342090854404605/*/1KS6Cxl4CJnSLkMcdgbnmEdsStlVzacWX [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-02-18 16:56:58--  https://doc-08-cc-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/eob5hsg3v7suni03f0jb173anaqnksc8/1613667375000/13802342090854404605/*/1KS6Cxl4CJnSLkMcdgbnmEdsStlVzacWX\n",
            "Resolving doc-08-cc-docs.googleusercontent.com (doc-08-cc-docs.googleusercontent.com)... 108.177.126.132, 2a00:1450:4013:c01::84\n",
            "Connecting to doc-08-cc-docs.googleusercontent.com (doc-08-cc-docs.googleusercontent.com)|108.177.126.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1859231 (1.8M) [text/csv]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]   1.77M  --.-KB/s    in 0.008s  \n",
            "\n",
            "2021-02-18 16:56:59 (216 MB/s) - ‘train.csv’ saved [1859231/1859231]\n",
            "\n",
            "--2021-02-18 16:56:59--  https://drive.google.com/u/0/uc?id=19WKir5IRn83NMcVgvNDrmgcDj1UIv7kt\n",
            "Resolving drive.google.com (drive.google.com)... 108.177.127.100, 108.177.127.113, 108.177.127.102, ...\n",
            "Connecting to drive.google.com (drive.google.com)|108.177.127.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0c-cc-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7akjj06lch758hegl5ib552aijnhrdqn/1613667375000/13802342090854404605/*/19WKir5IRn83NMcVgvNDrmgcDj1UIv7kt [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-02-18 16:56:59--  https://doc-0c-cc-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7akjj06lch758hegl5ib552aijnhrdqn/1613667375000/13802342090854404605/*/19WKir5IRn83NMcVgvNDrmgcDj1UIv7kt\n",
            "Resolving doc-0c-cc-docs.googleusercontent.com (doc-0c-cc-docs.googleusercontent.com)... 108.177.126.132, 2a00:1450:4013:c01::84\n",
            "Connecting to doc-0c-cc-docs.googleusercontent.com (doc-0c-cc-docs.googleusercontent.com)|108.177.126.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 424235 (414K) [text/csv]\n",
            "Saving to: ‘dev.csv’\n",
            "\n",
            "dev.csv             100%[===================>] 414.29K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2021-02-18 16:56:59 (138 MB/s) - ‘dev.csv’ saved [424235/424235]\n",
            "\n",
            "--2021-02-18 16:56:59--  https://drive.google.com/u/0/uc?id=11pyqg27tGRC1iDo26C2b01bMETqdUwuf\n",
            "Resolving drive.google.com (drive.google.com)... 108.177.127.102, 108.177.127.100, 108.177.127.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|108.177.127.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-70-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/adaqv6ru4l773aeps68edd3m739g0pu0/1613667375000/18042724966187936417/*/11pyqg27tGRC1iDo26C2b01bMETqdUwuf [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-02-18 16:57:00--  https://doc-04-70-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/adaqv6ru4l773aeps68edd3m739g0pu0/1613667375000/18042724966187936417/*/11pyqg27tGRC1iDo26C2b01bMETqdUwuf\n",
            "Resolving doc-04-70-docs.googleusercontent.com (doc-04-70-docs.googleusercontent.com)... 108.177.126.132, 2a00:1450:4013:c01::84\n",
            "Connecting to doc-04-70-docs.googleusercontent.com (doc-04-70-docs.googleusercontent.com)|108.177.126.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 525642 (513K) [text/csv]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "test.csv            100%[===================>] 513.32K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2021-02-18 16:57:00 (111 MB/s) - ‘test.csv’ saved [525642/525642]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VU17WM0m6y3"
      },
      "source": [
        "# Load data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TevikPkl010",
        "outputId": "d004087f-14c4-423e-9add-f887fc7c95dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Take a look at the data\r\n",
        "test_df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original1</th>\n",
              "      <th>edit1</th>\n",
              "      <th>original2</th>\n",
              "      <th>edit2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>704-2704</td>\n",
              "      <td>\" Pence Is Trying to Control Republican Politi...</td>\n",
              "      <td>barbers</td>\n",
              "      <td>\" Pence Is Trying to &lt;Control/&gt; Republican Pol...</td>\n",
              "      <td>Bungle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>704-14395</td>\n",
              "      <td>\" Pence Is Trying to Control Republican Politi...</td>\n",
              "      <td>barbers</td>\n",
              "      <td>\" &lt;Pence/&gt; Is Trying to Control Republican Pol...</td>\n",
              "      <td>Witch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2704-14395</td>\n",
              "      <td>\" Pence Is Trying to &lt;Control/&gt; Republican Pol...</td>\n",
              "      <td>Bungle</td>\n",
              "      <td>\" &lt;Pence/&gt; Is Trying to Control Republican Pol...</td>\n",
              "      <td>Witch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11098-10186</td>\n",
              "      <td>\" There is no Man Behind the Curtain , \" says ...</td>\n",
              "      <td>elephant</td>\n",
              "      <td>\" There is no Man Behind the Curtain , \" says ...</td>\n",
              "      <td>woman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11098-2118</td>\n",
              "      <td>\" There is no Man Behind the Curtain , \" says ...</td>\n",
              "      <td>elephant</td>\n",
              "      <td>\" There is no Man Behind the Curtain , \" says ...</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  ...   edit2\n",
              "0     704-2704  ...  Bungle\n",
              "1    704-14395  ...   Witch\n",
              "2   2704-14395  ...   Witch\n",
              "3  11098-10186  ...   woman\n",
              "4   11098-2118  ...     man\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSRS6PLHLAtf"
      },
      "source": [
        "## Download and unzip GLOVE Embeddings\r\n",
        "\r\n",
        "TODO: Do we bother using GLOVE at all? May be interesting in report to compare GLOVE vs BERT embeddings?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydxDrWAEpSjo",
        "outputId": "de67bfdd-f470-4db6-f8a5-386d002fd556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # Outputs will be saved in your google drive"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlEA5Hhym6y1"
      },
      "source": [
        "# You will need to download any word embeddings required for your code, e.g.:\n",
        "\n",
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "# !unzip glove.6B.zip\n",
        "\n",
        "# For any packages that Colab does not provide auotmatically you will also need to install these below, e.g.:\n",
        "\n",
        "#! pip install torch"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riXUwYsk9-TO",
        "outputId": "f6289e2e-a1ee-441d-b2c7-c016e406baaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip '/content/drive/MyDrive/cw/glove.6B.zip'"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/cw/glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd1-94s1MMgw"
      },
      "source": [
        "## Download and install Transformers library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTEI9ZFUwt0g",
        "outputId": "a4d8202e-91ad-494b-fa18-e6eda22cd5b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n",
            "\r\u001b[K     |▏                               | 10kB 19.4MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 27.2MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 30.0MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 21.1MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 15.5MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 14.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 71kB 13.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81kB 15.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 92kB 15.5MB/s eta 0:00:01\r\u001b[K     |█▉                              | 102kB 12.3MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 12.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 122kB 12.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 133kB 12.3MB/s eta 0:00:01\r\u001b[K     |██▌                             | 143kB 12.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 153kB 12.3MB/s eta 0:00:01\r\u001b[K     |███                             | 163kB 12.3MB/s eta 0:00:01\r\u001b[K     |███                             | 174kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 184kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 194kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 204kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 215kB 12.3MB/s eta 0:00:01\r\u001b[K     |████                            | 225kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 235kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 245kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 256kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 266kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 276kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 286kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 296kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 307kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 317kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 327kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 337kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 348kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 358kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 368kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 378kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 389kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 399kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 409kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 419kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 430kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 440kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 450kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 460kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 471kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 481kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 491kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 501kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 512kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 522kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 532kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 542kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 552kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 563kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 573kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 583kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 593kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 604kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 614kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 624kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 634kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 645kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 655kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 665kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 675kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 686kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 696kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 706kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 716kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 727kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 737kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 747kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 757kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 768kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 778kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 788kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 798kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 808kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 819kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 829kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 839kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 849kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 860kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 870kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 880kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 890kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 901kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 911kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 921kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 931kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 942kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 952kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 962kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 972kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 983kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 993kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.5MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.5MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.5MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.5MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.5MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.5MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.5MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.5MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.6MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.6MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.6MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.6MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.6MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.6MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.6MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.6MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.6MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.7MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.7MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.7MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.7MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.7MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.7MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.7MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.7MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.7MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.8MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.8MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.8MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.8MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.8MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8MB 12.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 56.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=3f950240bd7c191280c8d2d08fbb07f61321c1cf9f78a6fa06bc0c30fd985f2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ErHEDpRMfSv"
      },
      "source": [
        "## Training Evaluation Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZKyXkuFm6y5"
      },
      "source": [
        "# We define our training loop\n",
        "def train(train_iter, dev_iter, model, number_epoch, optimizer, scheduler=None):\n",
        "    \"\"\"\n",
        "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Training model.\")\n",
        "\n",
        "    for epoch in range(1, number_epoch+1):\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        epoch_loss = 0\n",
        "        epoch_correct = 0\n",
        "        no_observations = 0  # Observations used for training so far\n",
        "\n",
        "        for batch in train_iter:\n",
        "            feature, target = batch\n",
        "            feature, target = feature.to(device), target.to(device)\n",
        "\n",
        "            # for RNN:\n",
        "            model.batch_size = target.shape[0]\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "            # model.hidden = model.init_hidden()\n",
        "\n",
        "            predictions = model(feature).squeeze(1)\n",
        "            optimizer.zero_grad()\n",
        "            loss = loss_fn(predictions, target)\n",
        "\n",
        "            correct, __ = model_performance(np.argmax(predictions.detach().cpu().numpy(), axis=1), target.detach().cpu().numpy())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if scheduler:\n",
        "              scheduler.step()\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_correct += correct\n",
        "\n",
        "        valid_loss, valid_acc, __, __ = eval(dev_iter, model)\n",
        "\n",
        "        epoch_loss, epoch_acc = epoch_loss / no_observations, epoch_correct / no_observations\n",
        "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train Accuracy: {epoch_acc:.2f} | \\\n",
        "        Val. Loss: {valid_loss:.2f} | Val. Accuracy: {valid_acc:.2f} |')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUmf4mSTm6y6"
      },
      "source": [
        "# We evaluate performance on our dev set\n",
        "def eval(data_iter, model):\n",
        "    \"\"\"\n",
        "    Evaluating model performance on the dev set\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_correct = 0\n",
        "    pred_all = []\n",
        "    trg_all = []\n",
        "    no_observations = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_iter:\n",
        "            feature, target = batch\n",
        "\n",
        "            feature, target = feature.to(device), target.to(device)\n",
        "            \n",
        "            # for RNN:\n",
        "            model.batch_size = target.shape[0]\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "            # model.hidden = model.init_hidden()\n",
        "\n",
        "            predictions = model(feature).squeeze(1)\n",
        "            loss = loss_fn(predictions, target)\n",
        "\n",
        "            # We get the mse\n",
        "            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
        "            correct, __ = model_performance(np.argmax(pred, axis=1), trg)\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_correct += correct\n",
        "            pred_all.extend(pred)\n",
        "            trg_all.extend(trg)\n",
        "\n",
        "    return epoch_loss/no_observations, epoch_correct/no_observations, np.array(pred_all), np.array(trg_all)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wre27ok7m6y7"
      },
      "source": [
        "# How we print the model performance\n",
        "def model_performance(output, target, print_output=False):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    correct_answers = (output == target)\n",
        "    correct = sum(correct_answers)\n",
        "    acc = np.true_divide(correct,len(output))\n",
        "\n",
        "    if print_output:\n",
        "        print(f'| Acc: {acc:.2f} ')\n",
        "\n",
        "    return correct, acc"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWsWCL8NNBR0"
      },
      "source": [
        "def eval_test(data_iter, model):\n",
        "    \"\"\"\n",
        "    Evaluating model performance on the dev set\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    pred_all = []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_iter:\n",
        "            \n",
        "            batch = batch.to(device)\n",
        "            # for RNN:\n",
        "            model.batch_size = batch.shape[1]\n",
        "\n",
        "            predictions = model(batch).squeeze(1)\n",
        "\n",
        "            pred = predictions.detach().cpu().numpy()\n",
        "\n",
        "            pred_all.extend(pred)\n",
        "\n",
        "    return np.argmax(np.array(pred_all), axis=1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L9ZReWeMo7M"
      },
      "source": [
        "# Data augmentation and Vocab Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2qnkCm2M5QK"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkq5h2NF-VnS",
        "outputId": "a90f47c0-7add-4994-85b3-0b9b2a2bc5ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import re\n",
        "\n",
        "def substitute(sentence, edit):\n",
        "  open_pos = sentence.find('<')\n",
        "  close_pos = sentence.find('>')\n",
        "  sub = sentence.replace(sentence[open_pos: close_pos + 1], edit)\n",
        "  return sub\n",
        "\n",
        "def get_edited_df(df, test=False):\n",
        "  id = df['id']\n",
        "  edited1 = df.apply(lambda x:substitute(x['original1'], x['edit1']), axis=1)\n",
        "  edited2 = df.apply(lambda x:substitute(x['original2'], x['edit2']), axis=1)\n",
        "  combined = list(zip(edited1,edited2))\n",
        "  if test:\n",
        "    id = df['id']\n",
        "    combined = list(zip(id,edited1,edited2))\n",
        "    return pd.DataFrame(combined, columns=['id','edited1', 'edited2'])\n",
        "  return pd.DataFrame(combined, columns=['edited1', 'edited2'])\n",
        "\n",
        "edited_train_df = get_edited_df(train_df)\n",
        "edited_test_df = get_edited_df(test_df, True)\n",
        "\n",
        "edited_train_df.head()\n",
        "# edited_test_df.head()\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>edited1</th>\n",
              "      <th>edited2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\" Gene Cernan , Last Dancer on the Moon , Dies...</td>\n",
              "      <td>\" Gene Cernan , Last Astronaut on the Moon , i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\" I 'm done \" : Fed up with California , some ...</td>\n",
              "      <td>\" I 'm done \" : Fed up with pancakes , some co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\" I 'm done \" : Fed up with California , some ...</td>\n",
              "      <td>\" I 'm done \" : Fed up with life , some conser...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\" I 'm done \" : Fed up with pancakes , some co...</td>\n",
              "      <td>\" I 'm done \" : Fed up with life , some conser...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\" Our expectations of what civic engagement lo...</td>\n",
              "      <td>\" Our expectations of what civic engagement sm...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             edited1                                            edited2\n",
              "0  \" Gene Cernan , Last Dancer on the Moon , Dies...  \" Gene Cernan , Last Astronaut on the Moon , i...\n",
              "1  \" I 'm done \" : Fed up with California , some ...  \" I 'm done \" : Fed up with pancakes , some co...\n",
              "2  \" I 'm done \" : Fed up with California , some ...  \" I 'm done \" : Fed up with life , some conser...\n",
              "3  \" I 'm done \" : Fed up with pancakes , some co...  \" I 'm done \" : Fed up with life , some conser...\n",
              "4  \" Our expectations of what civic engagement lo...  \" Our expectations of what civic engagement sm..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp28SsNZ5HQR"
      },
      "source": [
        "## Define Vocab Class\r\n",
        "\r\n",
        "TODO: probs move this up to top and have functions for using GLOVE, BERT and our own"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3q9gLjl5TOq"
      },
      "source": [
        "class Vocabulary(object):\r\n",
        "  \"\"\"Data structure representing the vocabulary of a corpus.\"\"\"\r\n",
        "  def __init__(self):\r\n",
        "    # Mapping from tokens to integers\r\n",
        "    self._word2idx = {}\r\n",
        "\r\n",
        "    # Reverse-mapping from integers to tokens\r\n",
        "    self.idx2word = []\r\n",
        "\r\n",
        "  def word2idx(self, word, default=None):\r\n",
        "    \"\"\"Returns the integer ID of the word or default if not found.\"\"\"\r\n",
        "    return self._word2idx.get(word, default)\r\n",
        "\r\n",
        "  def add_word(self, word):\r\n",
        "    \"\"\"Adds the `word` into the vocabulary.\"\"\"\r\n",
        "    if word not in self._word2idx:\r\n",
        "      self.idx2word.append(word)\r\n",
        "      self._word2idx[word] = len(self.idx2word) - 1\r\n",
        "\r\n",
        "  def build_from_list(self, words):\r\n",
        "    for word in words:\r\n",
        "      self.add_word(word)\r\n",
        "\r\n",
        "  def build_from_file(self, fname):\r\n",
        "    \"\"\"Builds a vocabulary from a given corpus file.\"\"\"\r\n",
        "    with open(fname) as f:\r\n",
        "      for line in f:\r\n",
        "        words = line.strip().split()\r\n",
        "        for word in words:\r\n",
        "          self.add_word(word)\r\n",
        "\r\n",
        "  def convert_idxs_to_words(self, idxs):\r\n",
        "    \"\"\"Converts a list of indices to words.\"\"\"\r\n",
        "    return ' '.join(self.idx2word[idx] for idx in idxs)\r\n",
        "\r\n",
        "  def convert_words_to_idxs(self, words):\r\n",
        "    \"\"\"Converts a list of words to a list of indices.\"\"\"\r\n",
        "    return [self.word2idx(w) for w in words]\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    \"\"\"Returns the size of the vocabulary.\"\"\"\r\n",
        "    return len(self.idx2word)\r\n",
        "  \r\n",
        "  def __repr__(self):\r\n",
        "    return \"Vocabulary with {} items\".format(self.__len__())"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbw3d6ZFM8_E"
      },
      "source": [
        "## Vocab Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zub4c6BJm6y8"
      },
      "source": [
        "# To create our vocab (TODO: and return Vocabulary object)\n",
        "def create_vocab(data):\n",
        "    \"\"\"\n",
        "    Creating a corpus of all the tokens used\n",
        "    \"\"\"\n",
        "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
        "\n",
        "    for sentence_pair in data:\n",
        "        tokenized_sentence_pair = []\n",
        "        for sentence in sentence_pair:\n",
        "            tokenized_sentence = []\n",
        "\n",
        "            for token in sentence.split(' '): # simplest split is\n",
        "\n",
        "                tokenized_sentence.append(token.lower())\n",
        "\n",
        "            tokenized_sentence_pair.append(tokenized_sentence)\n",
        "        tokenized_corpus.append(tokenized_sentence_pair)\n",
        "\n",
        "    # Create single list of all vocabulary\n",
        "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
        "\n",
        "    for sentence_pair in tokenized_corpus:\n",
        "\n",
        "        for sentence in sentence_pair:\n",
        "\n",
        "            for token in sentence:\n",
        "\n",
        "                if token.lower() not in vocabulary:\n",
        "\n",
        "                    vocabulary.append(token.lower())\n",
        "\n",
        "    return vocabulary, tokenized_corpus"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAXn8XWBNnTW"
      },
      "source": [
        "TODO: Potentially break up code blocks a bit more?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qchTuXGrF0nb"
      },
      "source": [
        "The below code block loads in the GLOVE embeddings.\n",
        "TODO: We can move this into the Vocabulary class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTQ_arcRNEjK"
      },
      "source": [
        "## Load the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHerrK5LNJbG"
      },
      "source": [
        "### Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCEObxVMKUad"
      },
      "source": [
        "# We create a Dataset so we can create minibatches\n",
        "class Task2Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, train_data, labels):\n",
        "        self.x_train = train_data\n",
        "        self.y_train = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y_train)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.x_train[item], self.y_train[item]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD5PF9bnYsRk"
      },
      "source": [
        "### Creating Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yXQMGWHW_ti"
      },
      "source": [
        "def flip_label(label):\n",
        "  if label == 1:\n",
        "    return 2\n",
        "  elif label == 2:\n",
        "    return 1\n",
        "  else: \n",
        "    return label\n",
        "\n",
        "def create_dataloaders(feature, labels, collate_fn, train_proportion=0.8, batch_size=32, flip=True):\n",
        "    # 'feature' is a list of lists, each containing embedding IDs for word tokens\n",
        "    train_and_dev = Task2Dataset(feature, labels)\n",
        "\n",
        "    train_examples = round(len(train_and_dev)*train_proportion)\n",
        "    dev_examples = len(train_and_dev) - train_examples\n",
        "\n",
        "    train_dataset, dev_dataset = random_split(train_and_dev,\n",
        "                                              (train_examples,\n",
        "                                                dev_examples))\n",
        "\n",
        "    if flip:\n",
        "        # Add the reverse examples to the training set to create more training dara\n",
        "        flipped_train_dataset = []\n",
        "        for r in train_dataset:\n",
        "          flipped_train_dataset.append((list(reversed(r[0])), flip_label(r[1])))\n",
        "        train_dataset += flipped_train_dataset\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size, collate_fn=collate_fn)\n",
        "    dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "    \n",
        "    return train_loader, dev_loader\n",
        "\n",
        "def create_test_dataloader(feature, collate_fn, batch_size=32):\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(feature, batch_size=batch_size, collate_fn=collate_fn)\n",
        "    \n",
        "    return test_loader\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvXJ20y4m6y4"
      },
      "source": [
        "# Approach 1: Using pre-trained representations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SiCAvnONQCO"
      },
      "source": [
        "## 1.1 Using pre-trained (GloVe) embeddings with a BiLSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szdwn4PS-9_Y",
        "outputId": "1ac8bcac-4efa-4b94-bd93-63f4b1175c0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Approach 1 code, using functions defined above:\n",
        "\n",
        "# We set our training data and test data\n",
        "training_data = edited_train_df.values.tolist()\n",
        "test_data = np.array(edited_test_df.values.tolist())[:,1:].tolist()\n",
        "\n",
        "# Creating word vectors\n",
        "training_vocab, training_tokenized_corpus = create_vocab(training_data)\n",
        "test_vocab, test_tokenized_corpus = create_vocab(test_data)\n",
        "\n",
        "# Creating joint vocab from test and train\n",
        "# TODO: We can optimise to just use the previous two:\n",
        "joint_vocab, joint_tokenized_corpus = create_vocab(training_data + test_data)\n",
        "\n",
        "print(\"Vocab created.\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGQJ_QNYFu_p"
      },
      "source": [
        "# We create representations for our tokens\n",
        "wvecs = [] # word vectors\n",
        "\n",
        "vocab = Vocabulary()\n",
        "# This is a large file, it will take a while to load in the memory!\n",
        "with codecs.open('glove.6B.300d.txt', 'r','utf-8') as f:\n",
        "  index = 1\n",
        "  for line in f.readlines():\n",
        "    # Ignore the first line - first line typically contains vocab, dimensionality\n",
        "    if len(line.strip().split()) > 3:\n",
        "      word = line.strip().split()[0]\n",
        "      if word in joint_vocab:\n",
        "          (word, vec) = (word,\n",
        "                     list(map(float,line.strip().split()[1:])))\n",
        "          wvecs.append(vec)\n",
        "          vocab.add_word(word)\n",
        "\n",
        "\n",
        "wvecs = np.array(wvecs)\n",
        "\n",
        "vectorized_seqs = [[[vocab.word2idx(tok) for tok in sen if tok in vocab._word2idx] for sen in seq] for seq in training_tokenized_corpus]\n",
        "vectorized_test = [[[vocab.word2idx(tok) for tok in sen if tok in vocab._word2idx] for sen in seq] for seq in test_tokenized_corpus]\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1PYwPBfm6y9"
      },
      "source": [
        "# Used for collating our observations into minibatches:\n",
        "def collate_fn_padd(batch):\n",
        "    '''\n",
        "    We add padding to our minibatches and create tensors for our model\n",
        "    '''\n",
        "    \n",
        "    batch_labels = [l for f, l in batch]\n",
        "    batch_features = [f for f, l in batch]\n",
        "\n",
        "    batch_features_len = [[len(s) for s in f] for f, l in batch]\n",
        "\n",
        "    seq_tensor = torch.zeros((2, len(batch), np.max(batch_features_len))).long()\n",
        "\n",
        "    # Shape of seq_tensor is batch_size x max_feature_len\n",
        "    # It should be batch_size x 2 x max_feature_len\n",
        "\n",
        "    for idx, (seq, seqlens) in enumerate(zip(batch_features, batch_features_len)):\n",
        "        for i in range(2):\n",
        "            seq_tensor[i, idx, :seqlens[i]] = torch.LongTensor(seq[i])\n",
        "\n",
        "    batch_labels = torch.LongTensor(batch_labels)\n",
        "\n",
        "    return seq_tensor, batch_labels\n",
        "\n",
        "def collate_test(batch):\n",
        "    '''\n",
        "    We add padding to our minibatches and create tensors for our model\n",
        "    '''\n",
        "    \n",
        "    batch_features_len = [[len(s) for s in b] for b in batch]\n",
        "\n",
        "    seq_tensor = torch.zeros((2, len(batch), np.max(batch_features_len))).long()\n",
        "\n",
        "    # Shape of seq_tensor is batch_size x max_feature_len\n",
        "    # It should be batch_size x 2 x max_feature_len\n",
        "\n",
        "    for idx, (seq, seqlens) in enumerate(zip(batch, batch_features_len)):\n",
        "        for i in range(2):\n",
        "            seq_tensor[i, idx, :seqlens[i]] = torch.LongTensor(seq[i])\n",
        "\n",
        "    return seq_tensor"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfKwiK_pKQbe",
        "outputId": "4e77961a-0e23-4ecb-babf-d772ab74e5c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "feature = vectorized_seqs\n",
        "labels = list(train_df['label'])\n",
        "test_features = vectorized_test\n",
        "\n",
        "def flip_label(label):\n",
        "  if label == 1:\n",
        "    return 2\n",
        "  elif label == 2:\n",
        "    return 1\n",
        "  else: \n",
        "    return label\n",
        "\n",
        "train_loader, dev_loader = create_dataloaders(feature, labels, collate_fn_padd)\n",
        "test_loader = create_test_dataloader(test_features, collate_test)\n",
        "\n",
        "print(\"Dataloaders created.\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataloaders created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYyl1tpwm6y-"
      },
      "source": [
        "class BiLSTM_classification(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
        "        super(BiLSTM_classification, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2label = nn.Linear(hidden_dim * 4, 3)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embedding1 = self.embedding(sentence[0])\n",
        "        embedding1 = embedding1.permute(1, 0, 2)\n",
        "\n",
        "        embedding2 = self.embedding(sentence[1])\n",
        "        embedding2 = embedding2.permute(1, 0, 2)\n",
        "\n",
        "        lstm_out_1, _ = self.lstm(embedding1.view(len(embedding1), -1, self.embedding_dim))\n",
        "        lstm_out_2, _ = self.lstm(embedding2.view(len(embedding2), -1, self.embedding_dim))\n",
        "        # concat both lstm_out_1 and lstm_out_2 and give to our linear layer, think we need\n",
        "        # output shape of lstm_ out is 2 * hidden_size as we do it in both directions\n",
        " \n",
        "        # lstm_out_1[-1] are both batch_size x (2 * hidden_size)\n",
        "        # do we concat so it's (2*batch_size) x (2 * hidden_size) or batch_size x (2*(2 * hidden_size))? - I chose the latter\n",
        "        out = self.hidden2label(torch.cat((lstm_out_1[-1], lstm_out_2[-1]), 1))\n",
        "        return out"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZNzwrdrOFAq"
      },
      "source": [
        "TODO: Separate out dataset stuff and model stuff below and put data loading stuff in section above. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJtG2gnyD5AU",
        "outputId": "22679822-8cf9-471f-e76c-573b03f391cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Number of epochs\n",
        "epochs = 16\n",
        "\n",
        "INPUT_DIM = len(vocab) + 1\n",
        "HIDDEN_DIM = 400 # Higher appears to yield better val acc\n",
        "EMBEDDING_DIM = 300 # Higher yields better val acc\n",
        "\n",
        "## TODO: Figure out network dimensions\n",
        "model = BiLSTM_classification(EMBEDDING_DIM, HIDDEN_DIM, INPUT_DIM)\n",
        "print(\"Model initialised.\")\n",
        "\n",
        "model.to(device)\n",
        "# We provide the model with our embeddings\n",
        "model.embedding.weight.data[1:].copy_(torch.from_numpy(wvecs))\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialised.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
              "        [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n",
              "        [-0.1256,  0.0136,  0.1031,  ..., -0.3422, -0.0224,  0.1368],\n",
              "        ...,\n",
              "        [ 0.5028, -0.1677,  0.0193,  ...,  0.4927,  0.6148,  0.0180],\n",
              "        [ 0.1070, -0.0379,  0.2672,  ...,  0.2112,  0.3525,  0.1777],\n",
              "        [-0.1868, -0.2897, -0.0846,  ...,  0.2076,  0.5071,  0.3187]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtHLpfiYm6zA",
        "outputId": "daec33e5-e135-4699-982f-89c17e68bfb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "train(train_loader, dev_loader, model, epochs, optimizer)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model.\n",
            "| Epoch: 01 | Train Loss: 0.96 | Train Accuracy: 0.46 |         Val. Loss: 0.95 | Val. Accuracy: 0.47 |\n",
            "| Epoch: 02 | Train Loss: 0.79 | Train Accuracy: 0.65 |         Val. Loss: 0.97 | Val. Accuracy: 0.58 |\n",
            "| Epoch: 03 | Train Loss: 0.47 | Train Accuracy: 0.82 |         Val. Loss: 1.22 | Val. Accuracy: 0.59 |\n",
            "| Epoch: 04 | Train Loss: 0.28 | Train Accuracy: 0.89 |         Val. Loss: 1.47 | Val. Accuracy: 0.58 |\n",
            "| Epoch: 05 | Train Loss: 0.17 | Train Accuracy: 0.94 |         Val. Loss: 2.13 | Val. Accuracy: 0.59 |\n",
            "| Epoch: 06 | Train Loss: 0.12 | Train Accuracy: 0.96 |         Val. Loss: 2.40 | Val. Accuracy: 0.57 |\n",
            "| Epoch: 07 | Train Loss: 0.06 | Train Accuracy: 0.98 |         Val. Loss: 3.37 | Val. Accuracy: 0.58 |\n",
            "| Epoch: 08 | Train Loss: 0.04 | Train Accuracy: 0.99 |         Val. Loss: 3.22 | Val. Accuracy: 0.61 |\n",
            "| Epoch: 09 | Train Loss: 0.03 | Train Accuracy: 0.99 |         Val. Loss: 3.94 | Val. Accuracy: 0.60 |\n",
            "| Epoch: 10 | Train Loss: 0.02 | Train Accuracy: 0.99 |         Val. Loss: 3.18 | Val. Accuracy: 0.59 |\n",
            "| Epoch: 11 | Train Loss: 0.04 | Train Accuracy: 0.99 |         Val. Loss: 3.78 | Val. Accuracy: 0.61 |\n",
            "| Epoch: 12 | Train Loss: 0.02 | Train Accuracy: 0.99 |         Val. Loss: 3.91 | Val. Accuracy: 0.62 |\n",
            "| Epoch: 13 | Train Loss: 0.01 | Train Accuracy: 1.00 |         Val. Loss: 3.95 | Val. Accuracy: 0.62 |\n",
            "| Epoch: 14 | Train Loss: 0.01 | Train Accuracy: 1.00 |         Val. Loss: 4.79 | Val. Accuracy: 0.61 |\n",
            "| Epoch: 15 | Train Loss: 0.01 | Train Accuracy: 1.00 |         Val. Loss: 4.21 | Val. Accuracy: 0.60 |\n",
            "| Epoch: 16 | Train Loss: 0.01 | Train Accuracy: 1.00 |         Val. Loss: 4.02 | Val. Accuracy: 0.61 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZksGlYFGCJaL",
        "outputId": "3aae00ba-1296-4764-eeb1-2864be912a0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "test_results = eval_test(test_loader, model)\n",
        "\n",
        "id = edited_test_df['id']\n",
        "combined = list(zip(id,test_results))\n",
        "\n",
        "res = pd.DataFrame(combined, columns=['id', 'pred'])\n",
        "res.set_index('id', inplace=True, drop=True)\n",
        "\n",
        "res.to_csv('lstm.csv')\n",
        "\n",
        "res.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>704-2704</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>704-14395</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2704-14395</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11098-10186</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11098-2118</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             pred\n",
              "id               \n",
              "704-2704        2\n",
              "704-14395       2\n",
              "2704-14395      2\n",
              "11098-10186     0\n",
              "11098-2118      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX1hPU1F1liM"
      },
      "source": [
        "## 1.2 Using BERT embeddings\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI1fvZbE2cfg"
      },
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertModel \n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTIMdGWn4-AB"
      },
      "source": [
        "training_data = edited_train_df.values.tolist()\n",
        "test_data = edited_test_df.values.tolist()\n",
        "\n",
        "training_labels = train_df['label'].values.tolist()\n",
        "\n",
        "input_id_pairs = []\n",
        "\n",
        "for (sentence1, sentence2) in training_data:\n",
        "    encoded_sentence1 = tokenizer.encode(sentence1)\n",
        "    encoded_sentence2 = tokenizer.encode(sentence2)\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_id_pairs.append([encoded_sentence1, encoded_sentence2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMOZvK4e5BxV"
      },
      "source": [
        "# Used for collating our observations into minibatches:\n",
        "\n",
        "# Note that this one adds an attention mask (used to tell BERT to ignore padding)\n",
        "def collate_fn_padd_BERT_embeddings(batch):\n",
        "    '''\n",
        "    We add padding to our minibatches and create tensors for our model\n",
        "    '''\n",
        "    batch_labels = [l for f, l in batch]\n",
        "    batch_features = [f for f, l in batch]\n",
        "\n",
        "    batch_features_len = [[len(s) for s in f] for f, l in batch]\n",
        "\n",
        "    seq_tensor = torch.zeros((2, len(batch), np.max(batch_features_len))).long()\n",
        "    mask_tensor = torch.zeros((2, len(batch), np.max(batch_features_len))).long()\n",
        "\n",
        "    # Shape of seq_tensor is batch_size x max_feature_len\n",
        "    # It should be batch_size x 2 x max_feature_len\n",
        "\n",
        "    for idx, (seq, seqlens) in enumerate(zip(batch_features, batch_features_len)):\n",
        "        for i in range(2):\n",
        "            seq_tensor[i, idx, :seqlens[i]] = torch.LongTensor(seq[i])\n",
        "            mask_tensor[i, idx, :seqlens[i]] = torch.ones(seqlens[i])\n",
        "\n",
        "    batch_labels = torch.LongTensor(batch_labels)\n",
        "\n",
        "    feature_tensor = torch.stack([seq_tensor, mask_tensor], dim=1)\n",
        "    return feature_tensor, batch_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BskvIzc75ANM"
      },
      "source": [
        "train_loader, dev_loader = create_dataloaders(input_id_pairs, training_labels, collate_fn_padd_BERT_embeddings)\n",
        "\n",
        "print(\"Dataloaders created.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-6O_qyV_QpX"
      },
      "source": [
        "class BiLSTM_BERT_classification(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(BiLSTM_BERT_classification, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased',\n",
        "            output_hidden_states = True, \n",
        "        )\n",
        "        # The word embedding dimension given by concatenating last 4 hidden \n",
        "        # layers of BERT\n",
        "        self.embedding_dim = 3072\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(self.embedding_dim, hidden_dim, bidirectional=True)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2label = nn.Linear(hidden_dim * 4, 3)\n",
        "\n",
        "    def compute_embeddings(self, feature):\n",
        "        b_input_ids = feature[0].to(device)\n",
        "        b_input_mask = feature[1].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # We aren't trying to train BERT here, only use its embeddings\n",
        "            self.bert.eval()\n",
        "            outputs = self.bert(\n",
        "                b_input_ids,\n",
        "                attention_mask=b_input_mask\n",
        "            )\n",
        "            hidden_states = outputs.hidden_states\n",
        "        \n",
        "        return torch.cat([hidden_states[i] for i in [-1,-2,-3,-4]], dim=-1)\n",
        "\n",
        "    def forward(self, sentences):\n",
        "        embedding1 = self.compute_embeddings(sentences[0])\n",
        "        embedding1 = embedding1.permute(1, 0, 2)\n",
        "        embedding2 = self.compute_embeddings(sentences[1])\n",
        "        embedding2 = embedding2.permute(1, 0, 2)\n",
        "\n",
        "        lstm_out_1, _ = self.lstm(embedding1.view(len(embedding1), -1, self.embedding_dim))\n",
        "        lstm_out_2, _ = self.lstm(embedding2.view(len(embedding2), -1, self.embedding_dim))\n",
        "        # concat both lstm_out_1 and lstm_out_2 and give to our linear layer, think we need\n",
        "        # output shape of lstm_ out is 2 * hidden_size as we do it in both directions\n",
        " \n",
        "        # lstm_out_1[-1] are both batch_size x (2 * hidden_size)\n",
        "        # do we concat so it's (2*batch_size) x (2 * hidden_size) or batch_size x (2*(2 * hidden_size))? - I chose the latter\n",
        "        out = self.hidden2label(torch.cat((lstm_out_1[-1], lstm_out_2[-1]), 1))\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnHthd2vRugs"
      },
      "source": [
        "# Number of epochs\n",
        "epochs = 16\n",
        "\n",
        "HIDDEN_DIM = 400 # Higher appears to yield better val acc\n",
        "\n",
        "## TODO: Figure out network dimensions\n",
        "model = BiLSTM_BERT_classification(HIDDEN_DIM)\n",
        "print(\"Model initialised.\")\n",
        "\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc8eCtB4Sw36"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "train(train_loader, dev_loader, model, epochs, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2oL9RyRNRV-"
      },
      "source": [
        "test_results = eval_test(test_loader, model)\n",
        "\n",
        "id = edited_test_df['id']\n",
        "combined = list(zip(id,test_results))\n",
        "\n",
        "res = pd.DataFrame(combined, columns=['id', 'pred'])\n",
        "res.set_index('id', inplace=True, drop=True)\n",
        "\n",
        "res.to_csv('lstm.csv')\n",
        "\n",
        "res.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYAwjlV73uCE"
      },
      "source": [
        "## 1.3 Fine-tuning BERT\n",
        "\n",
        "The following code is basically just an initial attempt to fine-tune BERT for the task. \n",
        "A good amount of the code here is either inspired by or, in the case of the training loop, literally taken from this link: \n",
        "https://github.com/aniruddhachoudhury/BERT-Tutorials/blob/master/Blog%202/BERT_Fine_Tuning_Sentence_Classification.ipynb\n",
        "\n",
        "I know it needs a refactor. I just want it to work. \n",
        "\n",
        "I think we could also try to take some inspiration from the following two resources: \n",
        "\n",
        "- https://medium.com/@theoliao1998/humor-detection-with-a-bert-regressor-9dc0a821c294\n",
        "- https://arxiv.org/pdf/2004.12765.pdf\n",
        "- https://github.com/ceshine/pytorch-pretrained-BERT/blob/master/notebooks/Next%20Sentence%20Prediction.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtykWoYywy34"
      },
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "\n",
        "class HumourBert(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HumourBert, self).__init__()\n",
        "        self.bert = DistilBertForSequenceClassification.from_pretrained(\n",
        "            'distilbert-base-uncased', \n",
        "            num_labels = 3,\n",
        "            output_attentions = False,\n",
        "            output_hidden_states = False\n",
        "        )\n",
        "    \n",
        "    def forward(self, feature):\n",
        "        b_input_ids = feature[0].to(device)\n",
        "        b_input_mask = feature[1].to(device)\n",
        "        outputs = self.bert(\n",
        "            b_input_ids,\n",
        "            attention_mask=b_input_mask\n",
        "        )\n",
        "        return outputs.logits\n",
        "\n",
        "\n",
        "model = HumourBert().to(device)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19wLchAt1v7o"
      },
      "source": [
        "# We set our training data and test data\n",
        "training_data = edited_train_df.values.tolist()\n",
        "test_data = edited_test_df.values.tolist()\n",
        "\n",
        "training_labels = train_df['label'].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC4LgFjIxT2f"
      },
      "source": [
        "input_id_pairs = []\n",
        "\n",
        "cls = tokenizer.encode('[CLS]')\n",
        "sep = tokenizer.encode('[SEP]')\n",
        "\n",
        "for (sentence1, sentence2) in training_data:\n",
        "    encoded_sentence1 = tokenizer.encode(sentence1, add_special_tokens=False)\n",
        "    encoded_sentence2 = tokenizer.encode(sentence2, add_special_tokens=False)\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_id_pairs.append([encoded_sentence1, encoded_sentence2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HfM4Od83qe2"
      },
      "source": [
        "def collate_fn_BERT(batch):\n",
        "    '''\n",
        "    We add padding to our minibatches and create tensors for our model\n",
        "    '''\n",
        "    batch_labels = [l for f, l in batch]\n",
        "    # Add the CLS and SEP tokens here\n",
        "    batch_features = [cls + s1 + sep + s2 for (s1, s2), l in batch]\n",
        "\n",
        "    batch_features_len = [len(f) for f in batch_features]\n",
        "\n",
        "    seq_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\n",
        "    mask_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\n",
        "\n",
        "    for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\n",
        "        seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
        "        mask_tensor[idx, :seqlen] = torch.ones(seqlen)\n",
        "\n",
        "    batch_labels = torch.LongTensor(batch_labels)\n",
        "\n",
        "    # Put sequence and tensor together\n",
        "    feature_tensor = torch.stack([seq_tensor, mask_tensor])\n",
        "    \n",
        "    return feature_tensor, batch_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD6FY2Ue4NSK"
      },
      "source": [
        "train_loader, dev_loader = create_dataloaders(input_id_pairs, training_labels, collate_fn_BERT, flip=False)\n",
        "\n",
        "print(\"Dataloaders created.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEub9iOq7Hol"
      },
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                  lr = 1e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 16\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_loader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwbvaZHVGUFo"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "train(train_loader, dev_loader, model, epochs, optimizer, scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXBhmuk_m6zD"
      },
      "source": [
        "# Approach 2: No pre-trained representations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PigD29yW-UCI"
      },
      "source": [
        "TODO: Make code work with sentence pairs\r\n",
        "TODO: Can probably make below function part of Vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBXV9Ess-Sdr"
      },
      "source": [
        "# def corpus_to_tensor(_vocab, corpus):\r\n",
        "#   # Final token indices\r\n",
        "#   idxs = []\r\n",
        "  \r\n",
        "#   for sent in corpus:\r\n",
        "#         sent = f\"<s> {line} </s>\"\r\n",
        "#         # Split from whitespace and add sentence markers\r\n",
        "#         idxs.extend(_vocab.convert_words_to_idxs(line.split()))\r\n",
        "#   return torch.LongTensor(idxs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b33Dsrx-2gho"
      },
      "source": [
        "## Create word-index mappings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdmmpE8G2rDW"
      },
      "source": [
        "vocab = Vocabulary()\r\n",
        "\r\n",
        "# 0-padding token\r\n",
        "vocab.add_word('<pad>')\r\n",
        "# sentence start\r\n",
        "vocab.add_word('<s>')\r\n",
        "# sentence end\r\n",
        "vocab.add_word('</s>')\r\n",
        "# Unknown words\r\n",
        "vocab.add_word('<unk>')\r\n",
        "vocab.build_from_list(joint_vocab)\r\n",
        "print(vocab)\r\n",
        "print(vocab.convert_words_to_idxs('the dancer is on the moon'.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFIn7ZCNDwUr"
      },
      "source": [
        "## Prepare data\n",
        "TODO: Reduce duplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-HqFrNGDzLF"
      },
      "source": [
        "vectorized_seqs = [[[vocab._word2idx[tok] for tok in sen if tok in vocab._word2idx] for sen in seq] for seq in training_tokenized_corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcnsn3bfD7e_"
      },
      "source": [
        "train_loader, dev_loader = create_dataloaders(input_id_pairs, training_labels, collate_fn_padd)\n",
        "\n",
        "print(\"Dataloaders created.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVchsvzdCkNS"
      },
      "source": [
        "## Bi-LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX6tvWIPFJRl"
      },
      "source": [
        "# Number of epochs\n",
        "epochs = 16\n",
        "\n",
        "INPUT_DIM = len(vocab) + 1\n",
        "HIDDEN_DIM = 400 # Higher appears to yield better val acc\n",
        "EMBEDDING_DIM = 300 # Higher yields better val acc\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "## TODO: Figure out network dimensions\n",
        "model = BiLSTM_classification(EMBEDDING_DIM, HIDDEN_DIM, INPUT_DIM, BATCH_SIZE, device)\n",
        "print(\"Model initialised.\")\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW7vXWTpFOCB"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "train(train_loader, dev_loader, model, epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xv8trAe3BoE"
      },
      "source": [
        "## LSTM model with attention\r\n",
        "\r\n",
        "Below code was inspired by the following:\r\n",
        "\r\n",
        "\r\n",
        "*   https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\r\n",
        "*   https://medium.com/intel-student-ambassadors/implementing-attention-models-in-pytorch-f947034b3e66\r\n",
        "* https://www.kaggle.com/yshubham/simple-lstm-for-text-classification-with-attention\r\n",
        "* https://iopscience.iop.org/article/10.1088/1742-6596/1207/1/012008\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feZdUAuqA11n"
      },
      "source": [
        "class AttnLSTM(nn.Module):\r\n",
        "  \r\n",
        "  def __init__(self, embedding_dim, hidden_dim, output_dim, vocab_size, dropout_prop=0.1):\r\n",
        "    super(AttnLSTM, self).__init__()\r\n",
        "    \r\n",
        "    self.embedding_dim = embedding_dim\r\n",
        "    self.hidden_dim = hidden_dimm\r\n",
        "    self.output_dim = output_dim\r\n",
        "    self.dropout_prop = dropout_prop\r\n",
        "    \r\n",
        "    self.embedding = nn.Embedding(\r\n",
        "      num_embeddings=self.vocab_size, embedding_dim=self.embedding_dim,\r\n",
        "      padding_idx=0)\r\n",
        "    self.attn = nn.Linear(embedding_dim + hidden_dim, 1)\r\n",
        "    self.dropout = nn.Dropout(self.dropout_prop)\r\n",
        "    self.hidden = self.init_hidden()\r\n",
        "\r\n",
        "    self.lstm = nn.LSTM(hidden_dim + vocab_size, output_size)\r\n",
        "    self.final = nn.Linear(hideen_dim, output_dim)\r\n",
        "  \r\n",
        "  def init_hidden(self):\r\n",
        "    return (torch.zeros(1, 1, self.output_size),\r\n",
        "      torch.zeros(1, 1, self.output_size))\r\n",
        "  \r\n",
        "  def forward(self, input, prev_out):\r\n",
        "    embedded = self.embedding(input).view(1, 1, -1)\r\n",
        "    embedded = self.dropout(embedded)\r\n",
        "\r\n",
        "    # Use MLP attention\r\n",
        "    attn_weights = F.softmax(\r\n",
        "            self.attn(torch.cat((embedded[0], self.hidden[0]), 1)), dim=1)\r\n",
        "    \r\n",
        "    # TODO: How tf does this work?\r\n",
        "    attn_applied = torch.bmm(attn_weights.unsqueeze(0), \r\n",
        "                             prev_out.view(1, -1, self.hidden_dim))\r\n",
        "    \r\n",
        "    lstm_in = torch.cat((attn_applied, embedded), dim = 1)\r\n",
        "    \r\n",
        "    output, self.hidden = self.lstm(lstm_in.unsqueeze(0), self.hidden)\r\n",
        "    \r\n",
        "    output = self.final(output)\r\n",
        "\r\n",
        "    ## TODO: What about softmax / sigmoid?\r\n",
        "    # output = F.log_softmax(self.out(output[0]), dim=1)\r\n",
        "    \r\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSpdX_Oc3KcB"
      },
      "source": [
        "## Training BERT from scratch\r\n",
        "\r\n",
        "following code adapted from:\r\n",
        "https://huggingface.co/blog/how-to-train\r\n",
        "\r\n",
        "Tokenizer docs: https://github.com/huggingface/tokenizers/tree/master/bindings/pythonhttps://github.com/huggingface/tokenizers/tree/master/bindings/python\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xd-KhVp8vje"
      },
      "source": [
        "# TODO: Move to top\r\n",
        "from tokenizers import ByteLevelBPETokenizer\r\n",
        "\r\n",
        "# Initialize a tokenizer\r\n",
        "tokenizer = ByteLevelBPETokenizer()\r\n",
        "\r\n",
        "# TODO: tokenize text with filepath? pass in train.csv? convert to txt?\r\n",
        "\r\n",
        "# Customize training\r\n",
        "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\r\n",
        "    \"<s>\",\r\n",
        "    \"<pad>\",\r\n",
        "    \"</s>\",\r\n",
        "    \"<unk>\",\r\n",
        "    \"<mask>\",\r\n",
        "])\r\n",
        "\r\n",
        "# produces a vocab.json and a merges.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psVmTb2fB-Xv"
      },
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\r\n",
        "\r\n",
        "model = BertForSequenceClassification()\r\n",
        "\r\n",
        "training_args = TrainingArguments(\r\n",
        "    output_dir='./results',          # output directory\r\n",
        "    num_train_epochs=3,              # total # of training epochs\r\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\r\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\r\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\r\n",
        "    weight_decay=0.01,               # strength of weight decay\r\n",
        "    logging_dir='./logs',            # directory for storing logs\r\n",
        ")\r\n",
        "\r\n",
        "trainer = Trainer(\r\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\r\n",
        "    args=training_args,                  # training arguments, defined above\r\n",
        "    train_dataset=train_dataset,         # training dataset\r\n",
        "    eval_dataset=test_dataset            # evaluation dataset\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAhN57qU2toN"
      },
      "source": [
        "## Pre-provided code for approach 2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "V_l3AjbLm6zE"
      },
      "source": [
        "train_and_dev = train_df['edit1']\n",
        "\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(train_df['edit1'], train_df['label'],\n",
        "                                                                        test_size=(1-train_proportion),\n",
        "                                                                        random_state=42)\n",
        "\n",
        "# We train a Tf-idf model\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "train_counts = count_vect.fit_transform(training_data)\n",
        "transformer = TfidfTransformer().fit(train_counts)\n",
        "train_counts = transformer.transform(train_counts)\n",
        "naive_model = MultinomialNB().fit(train_counts, training_y)\n",
        "\n",
        "# Train predictions\n",
        "predicted_train = naive_model.predict(train_counts)\n",
        "\n",
        "# Calculate Tf-idf using train and dev, and validate on dev:\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\n",
        "\n",
        "test_counts = count_vect.transform(dev_data)\n",
        "\n",
        "test_counts = transformer.transform(test_counts)\n",
        "\n",
        "# Dev predictions\n",
        "predicted = naive_model.predict(test_counts)\n",
        "\n",
        "# We run the evaluation:\n",
        "print(\"\\nTrain performance:\")\n",
        "\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\n",
        "\n",
        "print(\"\\nDev performance:\")\n",
        "sse, mse = model_performance(predicted, dev_y, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpKDFO8ym6zE"
      },
      "source": [
        "#### Baseline for task 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhcP7AD6m6zE"
      },
      "source": [
        "# Baseline for the task\n",
        "pred_baseline = torch.zeros(len(dev_y)) + 1  # 1 is most common class\n",
        "print(\"\\nBaseline performance:\")\n",
        "sse, mse = model_performance(pred_baseline, torch.tensor(dev_y.values), True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}